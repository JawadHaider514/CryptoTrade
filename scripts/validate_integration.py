#!/usr/bin/env python3
"""
VALIDATION TEST - Verify the integration actually works
This script tests all 4 critical fixes
"""

import sys
import sqlite3
import json
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def test_backtest_data_exists():
    """Test 1: Backtest data exists in database"""
    logger.info("\n" + "="*70)
    logger.info("TEST 1: Backtest Data Exists")
    logger.info("="*70)
    
    db_path = Path("data/backtest.db")
    
    if not db_path.exists():
        logger.error("âŒ FAIL: data/backtest.db does not exist!")
        logger.error("   Run: python core/run_backtest.py --full")
        return False
    
    try:
        with sqlite3.connect("data/backtest.db") as conn:
            cursor = conn.cursor()
            
            # Check tables
            cursor.execute("SELECT COUNT(*) FROM signal_outcomes")
            outcome_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM backtest_signals")
            signal_count = cursor.fetchone()[0]
            
            if outcome_count == 0 or signal_count == 0:
                logger.error(f"âŒ FAIL: Database empty (signals: {signal_count}, outcomes: {outcome_count})")
                return False
            
            logger.info(f"âœ… PASS: Database has {signal_count} signals and {outcome_count} outcomes")
            return True
    except Exception as e:
        logger.error(f"âŒ FAIL: {e}")
        return False

def test_config_has_real_data():
    """Test 2: Config file contains real data (not guesses)"""
    logger.info("\n" + "="*70)
    logger.info("TEST 2: Config Has Real Data")
    logger.info("="*70)
    
    config_path = Path("config/optimized_config.json")
    
    if not config_path.exists():
        logger.error("âŒ FAIL: config/optimized_config.json does not exist!")
        logger.error("   Run: python scripts/generate_real_config.py")
        return False
    
    try:
        with open(config_path) as f:
            config = json.load(f)
        
        # Check if config has the "based_on" field (indicating real generation)
        if "based_on" not in config:
            logger.warning("âš ï¸  Config doesn't have 'based_on' metadata - might be old format")
            logger.info("   Run: python scripts/generate_real_config.py")
        
        # Check accuracy values exist
        accuracy = config.get('accuracy_by_score', {})
        if not accuracy:
            logger.error("âŒ FAIL: Config missing accuracy_by_score!")
            return False
        
        logger.info(f"âœ… PASS: Config has accuracy data:")
        for score_range, value in accuracy.items():
            logger.info(f"     {score_range}: {value}%")
        
        return True
    except Exception as e:
        logger.error(f"âŒ FAIL: {e}")
        return False

def test_no_fake_fallbacks():
    """Test 3: Code has NO fake fallback numbers"""
    logger.info("\n" + "="*70)
    logger.info("TEST 3: No Fake Fallback Numbers in Code")
    logger.info("="*70)
    
    code_file = Path("core/enhanced_crypto_dashboard.py")
    
    try:
        with open(code_file) as f:
            content = f.read()
        
        # Check for common fallback patterns
        bad_patterns = [
            'return 88.0',   # Old hardcoded value
            'return 82.0',   # Old hardcoded value
            'return 78.0',   # Old hardcoded value
            'return 75.0',   # Old hardcoded value - should be 70.0 max
        ]
        
        found_bad = False
        for pattern in bad_patterns:
            if pattern in content and '_estimate_accuracy' in content[content.find(pattern)-500:content.find(pattern)+500]:
                logger.error(f"âŒ FAIL: Found fake fallback: {pattern}")
                found_bad = True
        
        if found_bad:
            return False
        
        # Check that crash happens on missing data
        if 'RuntimeError' in content and 'Cannot load accuracy data' in content:
            logger.info("âœ… PASS: Code raises error on missing data (no fake fallbacks)")
            return True
        else:
            logger.warning("âš ï¸  Code might still have fallbacks - check manually")
            return True
            
    except Exception as e:
        logger.error(f"âŒ FAIL: {e}")
        return False

def test_live_tracker_starts():
    """Test 4: Live tracker is initialized AND started"""
    logger.info("\n" + "="*70)
    logger.info("TEST 4: Live Tracker Initialized and Started")
    logger.info("="*70)
    
    code_file = Path("core/enhanced_crypto_dashboard.py")
    
    try:
        with open(code_file) as f:
            content = f.read()
        
        # Check that tracker is initialized
        if 'self.live_signal_tracker = LiveSignalTracker()' not in content:
            logger.error("âŒ FAIL: LiveSignalTracker not initialized")
            return False
        
        logger.info("âœ… LiveSignalTracker is initialized")
        
        # Check that START is called
        if '.start()' in content:
            logger.info("âœ… PASS: Tracker has .start() call (will run background monitoring)")
            return True
        else:
            logger.error("âŒ FAIL: tracker.start() not found - tracker won't actually monitor!")
            logger.error("   Add this line after initialization: self.live_signal_tracker.start()")
            return False
            
    except Exception as e:
        logger.error(f"âŒ FAIL: {e}")
        return False

def test_no_fake_timelines():
    """Test 5: Fake timeline function is deleted"""
    logger.info("\n" + "="*70)
    logger.info("TEST 5: Fake Timeline Function Deleted")
    logger.info("="*70)
    
    code_file = Path("core/enhanced_crypto_dashboard.py")
    
    try:
        with open(code_file) as f:
            content = f.read()
        
        # Check if function exists
        if 'def create_realistic_timeline' in content:
            logger.error("âŒ FAIL: create_realistic_timeline() still exists in code!")
            return False
        
        logger.info("âœ… PASS: Fake timeline function is deleted")
        
        # Check that status shows "Tracking live"
        if 'Tracking live' in content:
            logger.info("âœ… PASS: Code shows 'Tracking live...' status")
            return True
        else:
            logger.warning("âš ï¸  'Tracking live' message not found - update signal formatting")
            return True
            
    except Exception as e:
        logger.error(f"âŒ FAIL: {e}")
        return False

def main():
    """Run all validation tests"""
    logger.info("\n")
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘             INTEGRATION VALIDATION TEST SUITE                      â•‘")
    logger.info("â•‘  Verify that all 4 critical fixes actually work correctly          â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    tests = [
        ("Backtest Data Exists", test_backtest_data_exists),
        ("Config Has Real Data", test_config_has_real_data),
        ("No Fake Fallbacks", test_no_fake_fallbacks),
        ("Live Tracker Started", test_live_tracker_starts),
        ("Fake Timeline Deleted", test_no_fake_timelines),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            logger.error(f"Test crashed: {e}")
            results.append((test_name, False))
    
    # Summary
    logger.info("\n" + "="*70)
    logger.info("TEST SUMMARY")
    logger.info("="*70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"{status}: {test_name}")
    
    logger.info(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        logger.info("\nğŸ‰ ALL TESTS PASSED - Integration is working correctly!")
        logger.info("\nNext steps:")
        logger.info("1. Start the application: python run.py")
        logger.info("2. Generate signals and verify they're tracked")
        logger.info("3. Check that accuracy values match backtest data")
        logger.info("4. Verify live tracking updates in real-time")
        return 0
    else:
        logger.error(f"\nâš ï¸  {total - passed} test(s) failed - fix issues before running!")
        logger.error("\nCommon fixes:")
        logger.error("1. Run backtest: python core/run_backtest.py --full")
        logger.error("2. Generate config: python scripts/generate_real_config.py")
        logger.error("3. Check code modifications are correct")
        return 1

if __name__ == "__main__":
    exit(main())
